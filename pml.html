<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title></title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: #990073
   }

   pre .number {
     color: #099;
   }

   pre .comment {
     color: #998;
     font-style: italic
   }

   pre .keyword {
     color: #900;
     font-weight: bold
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: #d14;
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>



<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<p>PRACTICAL MACHINE LEARNING COURSE PROJECT
SYNOPSIS</p>

<p>Given both training and test data from the following study:</p>

<p>First, I&#39;ll load the appropriate packages and set the seed for reproduceable results.</p>

<pre><code class="r">library(AppliedPredictiveModeling)
library(caret)
</code></pre>

<pre><code>## Loading required package: lattice
## Loading required package: ggplot2
</code></pre>

<pre><code class="r">library(rattle)
</code></pre>

<pre><code>## Error in library(rattle): there is no package called &#39;rattle&#39;
</code></pre>

<pre><code class="r">library(rpart.plot)
</code></pre>

<pre><code>## Loading required package: rpart
</code></pre>

<pre><code class="r">library(randomForest)
</code></pre>

<pre><code>## randomForest 4.6-10
## Type rfNews() to see new features/changes/bug fixes.
</code></pre>

<p>QUESTION</p>

<p>In the study, six participants participated in a dumbell lifting exercise five different ways. The five ways, as described in the study, were “exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E). Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes.”</p>

<p>By processing data gathered from accelerometers on the belt, forearm, arm, and dumbell of the participants in a machine learning algorithm, the question is can the appropriate activity quality (class A-E) be predicted?
INPUT DATA</p>

<p>The first step is to import the data and to verify that the training data and the test data are identical.</p>

<pre><code class="r"># Download data.
url_raw_training &lt;- &quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv&quot;
file_dest_training &lt;- &quot;pml-training.csv&quot;
url_raw_testing &lt;- &quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv&quot;
file_dest_testing &lt;- &quot;pml-testing.csv&quot;
# Import the data treating empty values as NA.
df_training &lt;- read.csv(file_dest_training, na.strings=c(&quot;NA&quot;,&quot;&quot;), header=TRUE)
colnames_train &lt;- colnames(df_training)
df_testing &lt;- read.csv(file_dest_testing, na.strings=c(&quot;NA&quot;,&quot;&quot;), header=TRUE)
colnames_test &lt;- colnames(df_testing)

# Verify that the column names (excluding classe and problem_id) are identical in the training and test set.
all.equal(colnames_train[1:length(colnames_train)-1], colnames_test[1:length(colnames_train)-1])
</code></pre>

<pre><code>## [1] TRUE
</code></pre>

<p>FEATURES</p>

<p>Having verified that the schema of both the training and testing sets are identical (excluding the final column representing the A-E class), I decided to eliminate both NA columns and other extraneous columns.</p>

<pre><code class="r"># Count the number of non-NAs in each col.
nonNAs &lt;- function(x) {
    as.vector(apply(x, 2, function(x) length(which(!is.na(x)))))
}

# Build vector of missing data or NA columns to drop.
colcnts &lt;- nonNAs(df_training)
drops &lt;- c()
for (cnt in 1:length(colcnts)) {
    if (colcnts[cnt] &lt; nrow(df_training)) {
        drops &lt;- c(drops, colnames_train[cnt])
    }
}

# Drop NA data and the first 7 columns as they&#39;re unnecessary for predicting.
df_training &lt;- df_training[,!(names(df_training) %in% drops)]
df_training &lt;- df_training[,8:length(colnames(df_training))]

df_testing &lt;- df_testing[,!(names(df_testing) %in% drops)]
df_testing &lt;- df_testing[,8:length(colnames(df_testing))]

# Show remaining columns.
colnames(df_training)
</code></pre>

<pre><code>##  [1] &quot;roll_belt&quot;            &quot;pitch_belt&quot;           &quot;yaw_belt&quot;            
##  [4] &quot;total_accel_belt&quot;     &quot;gyros_belt_x&quot;         &quot;gyros_belt_y&quot;        
##  [7] &quot;gyros_belt_z&quot;         &quot;accel_belt_x&quot;         &quot;accel_belt_y&quot;        
## [10] &quot;accel_belt_z&quot;         &quot;magnet_belt_x&quot;        &quot;magnet_belt_y&quot;       
## [13] &quot;magnet_belt_z&quot;        &quot;roll_arm&quot;             &quot;pitch_arm&quot;           
## [16] &quot;yaw_arm&quot;              &quot;total_accel_arm&quot;      &quot;gyros_arm_x&quot;         
## [19] &quot;gyros_arm_y&quot;          &quot;gyros_arm_z&quot;          &quot;accel_arm_x&quot;         
## [22] &quot;accel_arm_y&quot;          &quot;accel_arm_z&quot;          &quot;magnet_arm_x&quot;        
## [25] &quot;magnet_arm_y&quot;         &quot;magnet_arm_z&quot;         &quot;roll_dumbbell&quot;       
## [28] &quot;pitch_dumbbell&quot;       &quot;yaw_dumbbell&quot;         &quot;total_accel_dumbbell&quot;
## [31] &quot;gyros_dumbbell_x&quot;     &quot;gyros_dumbbell_y&quot;     &quot;gyros_dumbbell_z&quot;    
## [34] &quot;accel_dumbbell_x&quot;     &quot;accel_dumbbell_y&quot;     &quot;accel_dumbbell_z&quot;    
## [37] &quot;magnet_dumbbell_x&quot;    &quot;magnet_dumbbell_y&quot;    &quot;magnet_dumbbell_z&quot;   
## [40] &quot;roll_forearm&quot;         &quot;pitch_forearm&quot;        &quot;yaw_forearm&quot;         
## [43] &quot;total_accel_forearm&quot;  &quot;gyros_forearm_x&quot;      &quot;gyros_forearm_y&quot;     
## [46] &quot;gyros_forearm_z&quot;      &quot;accel_forearm_x&quot;      &quot;accel_forearm_y&quot;     
## [49] &quot;accel_forearm_z&quot;      &quot;magnet_forearm_x&quot;     &quot;magnet_forearm_y&quot;    
## [52] &quot;magnet_forearm_z&quot;     &quot;classe&quot;
</code></pre>

<pre><code class="r">colnames(df_testing)
</code></pre>

<pre><code>##  [1] &quot;roll_belt&quot;            &quot;pitch_belt&quot;           &quot;yaw_belt&quot;            
##  [4] &quot;total_accel_belt&quot;     &quot;gyros_belt_x&quot;         &quot;gyros_belt_y&quot;        
##  [7] &quot;gyros_belt_z&quot;         &quot;accel_belt_x&quot;         &quot;accel_belt_y&quot;        
## [10] &quot;accel_belt_z&quot;         &quot;magnet_belt_x&quot;        &quot;magnet_belt_y&quot;       
## [13] &quot;magnet_belt_z&quot;        &quot;roll_arm&quot;             &quot;pitch_arm&quot;           
## [16] &quot;yaw_arm&quot;              &quot;total_accel_arm&quot;      &quot;gyros_arm_x&quot;         
## [19] &quot;gyros_arm_y&quot;          &quot;gyros_arm_z&quot;          &quot;accel_arm_x&quot;         
## [22] &quot;accel_arm_y&quot;          &quot;accel_arm_z&quot;          &quot;magnet_arm_x&quot;        
## [25] &quot;magnet_arm_y&quot;         &quot;magnet_arm_z&quot;         &quot;roll_dumbbell&quot;       
## [28] &quot;pitch_dumbbell&quot;       &quot;yaw_dumbbell&quot;         &quot;total_accel_dumbbell&quot;
## [31] &quot;gyros_dumbbell_x&quot;     &quot;gyros_dumbbell_y&quot;     &quot;gyros_dumbbell_z&quot;    
## [34] &quot;accel_dumbbell_x&quot;     &quot;accel_dumbbell_y&quot;     &quot;accel_dumbbell_z&quot;    
## [37] &quot;magnet_dumbbell_x&quot;    &quot;magnet_dumbbell_y&quot;    &quot;magnet_dumbbell_z&quot;   
## [40] &quot;roll_forearm&quot;         &quot;pitch_forearm&quot;        &quot;yaw_forearm&quot;         
## [43] &quot;total_accel_forearm&quot;  &quot;gyros_forearm_x&quot;      &quot;gyros_forearm_y&quot;     
## [46] &quot;gyros_forearm_z&quot;      &quot;accel_forearm_x&quot;      &quot;accel_forearm_y&quot;     
## [49] &quot;accel_forearm_z&quot;      &quot;magnet_forearm_x&quot;     &quot;magnet_forearm_y&quot;    
## [52] &quot;magnet_forearm_z&quot;     &quot;problem_id&quot;
</code></pre>

<p>Given that we&#39;re already supplied with the raw sensor data, there&#39;s no need for Level 1 processing. However, while being careful not to overfit, some Level 2 processing is certainly worth attempting.</p>

<p>First, check for covariates that have virtually no variablility.</p>

<pre><code class="r">nsv &lt;- nearZeroVar(df_training, saveMetrics=TRUE)
nsv
</code></pre>

<pre><code>##                      freqRatio percentUnique zeroVar   nzv
## roll_belt             1.101904     6.7781062   FALSE FALSE
## pitch_belt            1.036082     9.3772296   FALSE FALSE
## yaw_belt              1.058480     9.9734991   FALSE FALSE
## total_accel_belt      1.063160     0.1477933   FALSE FALSE
## gyros_belt_x          1.058651     0.7134849   FALSE FALSE
## gyros_belt_y          1.144000     0.3516461   FALSE FALSE
## gyros_belt_z          1.066214     0.8612782   FALSE FALSE
## accel_belt_x          1.055412     0.8357966   FALSE FALSE
## accel_belt_y          1.113725     0.7287738   FALSE FALSE
## accel_belt_z          1.078767     1.5237998   FALSE FALSE
## magnet_belt_x         1.090141     1.6664968   FALSE FALSE
## magnet_belt_y         1.099688     1.5187035   FALSE FALSE
## magnet_belt_z         1.006369     2.3290184   FALSE FALSE
## roll_arm             52.338462    13.5256345   FALSE FALSE
## pitch_arm            87.256410    15.7323412   FALSE FALSE
## yaw_arm              33.029126    14.6570176   FALSE FALSE
## total_accel_arm       1.024526     0.3363572   FALSE FALSE
## gyros_arm_x           1.015504     3.2769341   FALSE FALSE
## gyros_arm_y           1.454369     1.9162165   FALSE FALSE
## gyros_arm_z           1.110687     1.2638875   FALSE FALSE
## accel_arm_x           1.017341     3.9598410   FALSE FALSE
## accel_arm_y           1.140187     2.7367241   FALSE FALSE
## accel_arm_z           1.128000     4.0362858   FALSE FALSE
## magnet_arm_x          1.000000     6.8239731   FALSE FALSE
## magnet_arm_y          1.056818     4.4439914   FALSE FALSE
## magnet_arm_z          1.036364     6.4468454   FALSE FALSE
## roll_dumbbell         1.022388    84.2065029   FALSE FALSE
## pitch_dumbbell        2.277372    81.7449801   FALSE FALSE
## yaw_dumbbell          1.132231    83.4828254   FALSE FALSE
## total_accel_dumbbell  1.072634     0.2191418   FALSE FALSE
## gyros_dumbbell_x      1.003268     1.2282132   FALSE FALSE
## gyros_dumbbell_y      1.264957     1.4167771   FALSE FALSE
## gyros_dumbbell_z      1.060100     1.0498420   FALSE FALSE
## accel_dumbbell_x      1.018018     2.1659362   FALSE FALSE
## accel_dumbbell_y      1.053061     2.3748853   FALSE FALSE
## accel_dumbbell_z      1.133333     2.0894914   FALSE FALSE
## magnet_dumbbell_x     1.098266     5.7486495   FALSE FALSE
## magnet_dumbbell_y     1.197740     4.3012945   FALSE FALSE
## magnet_dumbbell_z     1.020833     3.4451126   FALSE FALSE
## roll_forearm         11.589286    11.0895933   FALSE FALSE
## pitch_forearm        65.983051    14.8557741   FALSE FALSE
## yaw_forearm          15.322835    10.1467740   FALSE FALSE
## total_accel_forearm   1.128928     0.3567424   FALSE FALSE
## gyros_forearm_x       1.059273     1.5187035   FALSE FALSE
## gyros_forearm_y       1.036554     3.7763735   FALSE FALSE
## gyros_forearm_z       1.122917     1.5645704   FALSE FALSE
## accel_forearm_x       1.126437     4.0464784   FALSE FALSE
## accel_forearm_y       1.059406     5.1116094   FALSE FALSE
## accel_forearm_z       1.006250     2.9558659   FALSE FALSE
## magnet_forearm_x      1.012346     7.7667924   FALSE FALSE
## magnet_forearm_y      1.246914     9.5403119   FALSE FALSE
## magnet_forearm_z      1.000000     8.5771073   FALSE FALSE
## classe                1.469581     0.0254816   FALSE FALSE
</code></pre>

<p>Given that all of the near zero variance variables (nsv) are FALSE, there&#39;s no need to eliminate any covariates due to lack of variablility.
ALGORITHM</p>

<p>We were provided with a large training set (19,622 entries) and a small testing set (20 entries). Instead of performing the algorithm on the entire training set, as it would be time consuming and wouldn&#39;t allow for an attempt on a testing set, I chose to divide the given training set into four roughly equal sets, each of which was then split into a training set (comprising 60% of the entries) and a testing set (comprising 40% of the entries).</p>

<pre><code class="r"># Divide the given training set into 4 roughly equal sets.
set.seed(666)
ids_small &lt;- createDataPartition(y=df_training$classe, p=0.25, list=FALSE)
df_small1 &lt;- df_training[ids_small,]
df_remainder &lt;- df_training[-ids_small,]
set.seed(666)
ids_small &lt;- createDataPartition(y=df_remainder$classe, p=0.33, list=FALSE)
df_small2 &lt;- df_remainder[ids_small,]
df_remainder &lt;- df_remainder[-ids_small,]
set.seed(666)
ids_small &lt;- createDataPartition(y=df_remainder$classe, p=0.5, list=FALSE)
df_small3 &lt;- df_remainder[ids_small,]
df_small4 &lt;- df_remainder[-ids_small,]
# Divide each of these 4 sets into training (60%) and test (40%) sets.
set.seed(666)
inTrain &lt;- createDataPartition(y=df_small1$classe, p=0.6, list=FALSE)
df_small_training1 &lt;- df_small1[inTrain,]
df_small_testing1 &lt;- df_small1[-inTrain,]
set.seed(666)
inTrain &lt;- createDataPartition(y=df_small2$classe, p=0.6, list=FALSE)
df_small_training2 &lt;- df_small2[inTrain,]
df_small_testing2 &lt;- df_small2[-inTrain,]
set.seed(666)
inTrain &lt;- createDataPartition(y=df_small3$classe, p=0.6, list=FALSE)
df_small_training3 &lt;- df_small3[inTrain,]
df_small_testing3 &lt;- df_small3[-inTrain,]
set.seed(666)
inTrain &lt;- createDataPartition(y=df_small4$classe, p=0.6, list=FALSE)
df_small_training4 &lt;- df_small4[inTrain,]
df_small_testing4 &lt;- df_small4[-inTrain,]
</code></pre>

<p>Based on both the process outlined in Section 5.2 of the aforementioned paper and the concensus in the coursera discussion forums, I chose two different algorithms via the caret package: classification trees (method = rpart) and random forests (method = rf).
PARAMETERS</p>

<p>I decided to try classification trees “out of the box” and then introduce preprocessing and cross validation.</p>

<p>EVALUATION
Classification Tree</p>

<p>First, the “out of the box” classification tree:</p>

<pre><code class="r"># Train on training set 1 of 4 with no extra features.
set.seed(666)
modFit &lt;- train(df_small_training1$classe ~ ., data = df_small_training1, method=&quot;rpart&quot;)
</code></pre>

<pre><code>## Error in loadNamespace(name): there is no package called &#39;e1071&#39;
</code></pre>

<pre><code class="r">print(modFit, digits=3)
</code></pre>

<pre><code>## Error in print(modFit, digits = 3): object &#39;modFit&#39; not found
</code></pre>

<pre><code class="r">print(modFit$finalModel, digits=3)
</code></pre>

<pre><code>## Error in print(modFit$finalModel, digits = 3): object &#39;modFit&#39; not found
</code></pre>

<pre><code class="r">fancyRpartPlot(modFit$finalModel)
</code></pre>

<pre><code>## Error in eval(expr, envir, enclos): could not find function &quot;fancyRpartPlot&quot;
</code></pre>

<pre><code class="r"># Run against testing set 1 of 4 with no extra features.
predictions &lt;- predict(modFit, newdata=df_small_testing1)
</code></pre>

<pre><code>## Error in predict(modFit, newdata = df_small_testing1): object &#39;modFit&#39; not found
</code></pre>

<pre><code class="r">print(confusionMatrix(predictions, df_small_testing1$classe), digits=4)
</code></pre>

<pre><code>## Error in confusionMatrix(predictions, df_small_testing1$classe): object &#39;predictions&#39; not found
</code></pre>

<p>Due to low accuracy rate (0.5584), I am incorporating preprocessing and/or cross validation.</p>

<pre><code class="r"># Train on training set 1 of 4 with only preprocessing.
set.seed(666)
modFit &lt;- train(df_small_training1$classe ~ .,  preProcess=c(&quot;center&quot;, &quot;scale&quot;), data = df_small_training1, method=&quot;rpart&quot;)
</code></pre>

<pre><code>## Error in loadNamespace(name): there is no package called &#39;e1071&#39;
</code></pre>

<pre><code class="r">print(modFit, digits=3)
</code></pre>

<pre><code>## Error in print(modFit, digits = 3): object &#39;modFit&#39; not found
</code></pre>

<pre><code class="r"># Train on training set 1 of 4 with only cross validation.
set.seed(666)
modFit &lt;- train(df_small_training1$classe ~ .,  trControl=trainControl(method = &quot;cv&quot;, number = 4), data = df_small_training1, method=&quot;rpart&quot;)
</code></pre>

<pre><code>## Error in loadNamespace(name): there is no package called &#39;e1071&#39;
</code></pre>

<pre><code class="r">print(modFit, digits=3)
</code></pre>

<pre><code>## Error in print(modFit, digits = 3): object &#39;modFit&#39; not found
</code></pre>

<pre><code class="r"># Train on training set 1 of 4 with both preprocessing and cross validation.
set.seed(666)
modFit &lt;- train(df_small_training1$classe ~ .,  preProcess=c(&quot;center&quot;, &quot;scale&quot;), trControl=trainControl(method = &quot;cv&quot;, number = 4), data = df_small_training1, method=&quot;rpart&quot;)
</code></pre>

<pre><code>## Error in loadNamespace(name): there is no package called &#39;e1071&#39;
</code></pre>

<pre><code class="r">print(modFit, digits=3)
</code></pre>

<pre><code>## Error in print(modFit, digits = 3): object &#39;modFit&#39; not found
</code></pre>

<pre><code class="r">## The final value used for the model was cp = 0.0346.

# Run against testing set 1 of 4 with both preprocessing and cross validation.
predictions &lt;- predict(modFit, newdata=df_small_testing1)
</code></pre>

<pre><code>## Error in predict(modFit, newdata = df_small_testing1): object &#39;modFit&#39; not found
</code></pre>

<pre><code class="r">print(confusionMatrix(predictions, df_small_testing1$classe), digits=4)
</code></pre>

<pre><code>## Error in confusionMatrix(predictions, df_small_testing1$classe): object &#39;predictions&#39; not found
</code></pre>

<p>The impact of incorporating both preprocessing and cross validation appeared to show some minimal improvement (accuracy rate rose from 0.531 to 0.552 against training sets). However, when run against the corresponding testing set, the accuracy rate was identical (0.5584) for both the “out of the box” and the preprocessing/cross validation methods.
Random Forest</p>

<p>First I decided to assess the impact/value of including preprocessing.</p>

<pre><code class="r"># Train on training set 1 of 4 with only cross validation.
set.seed(666)
modFit &lt;- train(df_small_training1$classe ~ ., method=&quot;rf&quot;, trControl=trainControl(method = &quot;cv&quot;, number = 4), data=df_small_training1)
</code></pre>

<pre><code>## Error in loadNamespace(name): there is no package called &#39;e1071&#39;
</code></pre>

<pre><code class="r">print(modFit, digits=3)
</code></pre>

<pre><code>## Error in print(modFit, digits = 3): object &#39;modFit&#39; not found
</code></pre>

<pre><code class="r"># Run against testing set 1 of 4.
predictions &lt;- predict(modFit, newdata=df_small_testing1)
</code></pre>

<pre><code>## Error in predict(modFit, newdata = df_small_testing1): object &#39;modFit&#39; not found
</code></pre>

<pre><code class="r">print(confusionMatrix(predictions, df_small_testing1$classe), digits=4)
</code></pre>

<pre><code>## Error in confusionMatrix(predictions, df_small_testing1$classe): object &#39;predictions&#39; not found
</code></pre>

<pre><code class="r"># Run against 20 testing set provided by Professor Leek.
print(predict(modFit, newdata=df_testing))
</code></pre>

<pre><code>## Error in predict(modFit, newdata = df_testing): object &#39;modFit&#39; not found
</code></pre>

<pre><code class="r"># Train on training set 1 of 4 with only both preprocessing and cross validation.
set.seed(666)
modFit &lt;- train(df_small_training1$classe ~ ., method=&quot;rf&quot;, preProcess=c(&quot;center&quot;, &quot;scale&quot;), trControl=trainControl(method = &quot;cv&quot;, number = 4), data=df_small_training1)
</code></pre>

<pre><code>## Error in loadNamespace(name): there is no package called &#39;e1071&#39;
</code></pre>

<pre><code class="r">print(modFit, digits=3)
</code></pre>

<pre><code>## Error in print(modFit, digits = 3): object &#39;modFit&#39; not found
</code></pre>

<pre><code class="r"># Run against testing set 1 of 4.
predictions &lt;- predict(modFit, newdata=df_small_testing1)
</code></pre>

<pre><code>## Error in predict(modFit, newdata = df_small_testing1): object &#39;modFit&#39; not found
</code></pre>

<pre><code class="r">print(confusionMatrix(predictions, df_small_testing1$classe), digits=4)
</code></pre>

<pre><code>## Error in confusionMatrix(predictions, df_small_testing1$classe): object &#39;predictions&#39; not found
</code></pre>

<pre><code class="r"># Run against 20 testing set provided by Professor Leek.
print(predict(modFit, newdata=df_testing))
</code></pre>

<pre><code>## Error in predict(modFit, newdata = df_testing): object &#39;modFit&#39; not found
</code></pre>

<p>Preprocessing actually lowered the accuracy rate from 0.955 to 0.954 against the training set. However, when run against the corresponding set, the accuracy rate rose from 0.9689 to 0.9714 with the addition of preprocessing. Thus I decided to apply both preprocessing and cross validation to the remaining 3 data sets.</p>

<pre><code class="r"># Train on training set 2 of 4 with only cross validation.
set.seed(666)
modFit &lt;- train(df_small_training2$classe ~ ., method=&quot;rf&quot;, preProcess=c(&quot;center&quot;, &quot;scale&quot;), trControl=trainControl(method = &quot;cv&quot;, number = 4), data=df_small_training2)
</code></pre>

<pre><code>## Error in loadNamespace(name): there is no package called &#39;e1071&#39;
</code></pre>

<pre><code class="r">print(modFit, digits=3)
</code></pre>

<pre><code>## Error in print(modFit, digits = 3): object &#39;modFit&#39; not found
</code></pre>

<pre><code class="r"># Run against testing set 2 of 4.
predictions &lt;- predict(modFit, newdata=df_small_testing2)
</code></pre>

<pre><code>## Error in predict(modFit, newdata = df_small_testing2): object &#39;modFit&#39; not found
</code></pre>

<pre><code class="r">print(confusionMatrix(predictions, df_small_testing2$classe), digits=4)
</code></pre>

<pre><code>## Error in confusionMatrix(predictions, df_small_testing2$classe): object &#39;predictions&#39; not found
</code></pre>

<pre><code class="r"># Run against 20 testing set provided by Professor Leek.
print(predict(modFit, newdata=df_testing))
</code></pre>

<pre><code>## Error in predict(modFit, newdata = df_testing): object &#39;modFit&#39; not found
</code></pre>

<pre><code class="r"># Train on training set 3 of 4 with only cross validation.
set.seed(666)
modFit &lt;- train(df_small_training3$classe ~ ., method=&quot;rf&quot;, preProcess=c(&quot;center&quot;, &quot;scale&quot;), trControl=trainControl(method = &quot;cv&quot;, number = 4), data=df_small_training3)
</code></pre>

<pre><code>## Error in loadNamespace(name): there is no package called &#39;e1071&#39;
</code></pre>

<pre><code class="r">print(modFit, digits=3)
</code></pre>

<pre><code>## Error in print(modFit, digits = 3): object &#39;modFit&#39; not found
</code></pre>

<pre><code class="r"># Run against testing set 3 of 4.
predictions &lt;- predict(modFit, newdata=df_small_testing3)
</code></pre>

<pre><code>## Error in predict(modFit, newdata = df_small_testing3): object &#39;modFit&#39; not found
</code></pre>

<pre><code class="r">print(confusionMatrix(predictions, df_small_testing3$classe), digits=4)
</code></pre>

<pre><code>## Error in confusionMatrix(predictions, df_small_testing3$classe): object &#39;predictions&#39; not found
</code></pre>

<pre><code class="r"># Run against 20 testing set provided by Professor Leek.
print(predict(modFit, newdata=df_testing))
</code></pre>

<pre><code>## Error in predict(modFit, newdata = df_testing): object &#39;modFit&#39; not found
</code></pre>

<pre><code class="r"># Train on training set 4 of 4 with only cross validation.
set.seed(666)
modFit &lt;- train(df_small_training4$classe ~ ., method=&quot;rf&quot;, preProcess=c(&quot;center&quot;, &quot;scale&quot;), trControl=trainControl(method = &quot;cv&quot;, number = 4), data=df_small_training4)
</code></pre>

<pre><code>## Error in loadNamespace(name): there is no package called &#39;e1071&#39;
</code></pre>

<pre><code class="r">print(modFit, digits=3)
</code></pre>

<pre><code>## Error in print(modFit, digits = 3): object &#39;modFit&#39; not found
</code></pre>

<pre><code class="r"># Run against testing set 4 of 4.
predictions &lt;- predict(modFit, newdata=df_small_testing4)
</code></pre>

<pre><code>## Error in predict(modFit, newdata = df_small_testing4): object &#39;modFit&#39; not found
</code></pre>

<pre><code class="r">print(confusionMatrix(predictions, df_small_testing4$classe), digits=4)
</code></pre>

<pre><code>## Error in confusionMatrix(predictions, df_small_testing4$classe): object &#39;predictions&#39; not found
</code></pre>

<pre><code class="r"># Run against 20 testing set provided by Professor Leek.
print(predict(modFit, newdata=df_testing))
</code></pre>

<pre><code>## Error in predict(modFit, newdata = df_testing): object &#39;modFit&#39; not found
</code></pre>

<p>Out of Sample Error</p>

<p>The out of sample error is the “error rate you get on new data set.” In my case, it&#39;s the error rate after running the predict() function on the 4 testing sets:</p>

<pre><code>Random Forest (preprocessing and cross validation) Testing Set 1: 1 - .9714 = 0.0286
Random Forest (preprocessing and cross validation) Testing Set 2: 1 - .9634 = 0.0366
Random Forest (preprocessing and cross validation) Testing Set 3: 1 - .9655 = 0.0345
Random Forest (preprocessing and cross validation) Testing Set 4: 1 - .9563 = 0.0437
</code></pre>

<p>Since each testing set is roughly of equal size, I decided to average the out of sample error rates derived by applying the random forest method with both preprocessing and cross validation against test sets 1-4 yielding a predicted out of sample rate of 0.03585.</p>

<p>CONCLUSION</p>

<p>I received three separate predictions by appling the 4 models against the actual 20 item training set:</p>

<p>A) Accuracy Rate 0.0286 Predictions: B A A A A E D B A A B C B A E E A B B B</p>

<p>B) Accuracy Rates 0.0366 and 0.0345 Predictions: B A B A A E D B A A B C B A E E A B B B</p>

<p>C) Accuracy Rate 0.0437 Predictions: B A B A A E D D A A B C B A E E A B B B</p>

<p>Since Professor Leek is allowing 2 submissions for each problem, I decided to attempt with the two most likely prediction sets: option A and option B.</p>

<p>Since options A and B above only differed for item 3 (A for option A, B for option B), I subimitted one value for problems 1-2 and 4-20, while I submitted two values for problem 3. For problem 3, I was expecting the automated grader to tell me which answer (A or B) was correct, but instead the grader simply told me I had a correct answer. All other answers were also correct, resulting in a score of 100%.</p>

</body>

</html>
